This experiment is for facial action unit recognition using the adaptive convolutional neural networks. Our input image after augmentation is 122*90 with one channel. After the first convolutional layer, the size is still 122*90 with 32 channels. After a 3*3 stride pooling, the size becomes 41*30 with 32 channels. 

In the forward process, the convolutional layer first convert the input image to column formate for the convenient of convolution operation. || can divide the parameter of first layer convolution and second layer convolution. 
```
        im2col_gpu(data, conv_in_channels_,//1|32
            conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],//122,90||41,30
            kernel_shape_max_.cpu_data()[0], kernel_shape_max_.cpu_data()[1],//9,9
            pad_.cpu_data()[0], pad_.cpu_data()[1],//4,4
            stride_.cpu_data()[0], stride_.cpu_data()[1],//1,1
            dilation_.cpu_data()[0], dilation_.cpu_data()[1], col_buff);
```
Then compute the matrix multiplication between weight and input col data:
```
    caffe_gpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, conv_out_channels_ /
            group_, conv_out_spatial_dim_, kernel_dim_,
        (Dtype)1., weights_up + weight_offset_ * g, col_buff + col_offset_ * g,
        (Dtype)0., output + output_offset_ * g);
        ```
where *group* is used to decrease the GPU memory consuming by dividing the channels to groups. 
