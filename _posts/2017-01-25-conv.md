This experiment is for facial action unit recognition using the adaptive convolutional neural networks. Our input image after augmentation is 122*90 with one channel. After the first convolutional layer, the size is still 122*90 with 32 channels. After a 3*3 stride pooling, the size becomes 41*30 with 32 channels. 

In the forward process, the convolutional layer first convert the input image to column formate for the convenient of convolution operation. || can divide the parameter of first layer convolution and second layer convolution. 
```
        im2col_gpu(data, conv_in_channels_,//1|32
            conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],//122,90||41,30
            kernel_shape_max_.cpu_data()[0], kernel_shape_max_.cpu_data()[1],//9,9
            pad_.cpu_data()[0], pad_.cpu_data()[1],//4,4
            stride_.cpu_data()[0], stride_.cpu_data()[1],//1,1
            dilation_.cpu_data()[0], dilation_.cpu_data()[1], col_buff);
```
Then compute the matrix multiplication between weight and input col data:
```
    caffe_gpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, conv_out_channels_ / //32
            group_, conv_out_spatial_dim_, kernel_dim_, //10980 81 || 1230 2592
        (Dtype)1., weights_up + weight_offset_ * g, col_buff + col_offset_ * g, //2592 889380 || 82944 3188160
        (Dtype)0., output + output_offset_ * g); //351360 || 39360
```
where group is used to decrease the GPU memory consuming by dividing the channels to groups. 
First convolutional layer:
conv_out_channels_: 32
conv_out_spatial_dim_=feature_out_h*feature_out_w=122*90
kernel_dim_=conv_in_channels_*kernel_height_*kernel_width_=1*9*9
weight_offset=conv_in_channels_*conv_out_channels_*kernel_height_*kernel_width_=1*32*9*9
col_offset_=kernel_dim_* conv_out_spatial_dim_=1*9*9*122*90=889380
ouput_offset_=conv_out_channels_ * conv_out_spatial_dim_/group_=32*122*90=351360
Second convolutoinal layer:
conv_out_channels_: 32
conv_out_spatial_dim_=feature_out_h*feature_out_w=41*30
kernel_dim_=conv_in_channels_*kernel_height_*kernel_width_=32*9*9
weight_offset=conv_in_channels_*conv_out_channels_*kernel_height_*kernel_width_=32*32*9*9
col_offset_=kernel_dim_* conv_out_spatial_dim_=32*9*9*41*30=3188160
ouput_offset_=conv_out_channels_ * conv_out_spatial_dim_/group_=32*41*30/1=39360
